{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e68b821b",
   "metadata": {},
   "source": [
    "# Active sampling code\n",
    "## Test case using Rastrigin function as objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fded810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime as time\n",
    "import dill\n",
    "# apply cache/archive in 3D same as 1D\n",
    "import mystic.cache as mc\n",
    "import dataset as ds\n",
    "import mystic.math.legacydata as ld\n",
    "from mystic.math.interpolate import _unique as unique\n",
    "import interpolator as itp\n",
    "from mystic.monitors import Monitor\n",
    "import dataset as ds\n",
    "import multiprocess.dummy as mp #FIXME: fails processes\n",
    "from mystic.monitors import LoggingMonitor\n",
    "import itertools as it\n",
    "# select solver and searcher algorithms\n",
    "from mystic.solvers import NelderMeadSimplexSolver as solver\n",
    "from mystic.samplers import *\n",
    "searcher = SparsitySampler\n",
    "#searcher = BuckshotSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ad23d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (2,0) #FIXME: rastrigin\n",
    "\n",
    "mname = 'demo'  # dynamic 'model' name\n",
    "fname = 'dirty' # static 'data' name\n",
    "pname = 'demo'  # hyper_plot name\n",
    "ename = 'stop'  # termination name\n",
    "\n",
    "etol = 1 # None # int rounding precision for termination point cache\n",
    "npts = 2 # 125 #125 #2 #500 # number of solvers used in a searcher\n",
    "upper = 10 #FIXME: 1000  # upper bound on input parameters\n",
    "bounds = [(0.,upper)] * shape[0] # bounds (lower is zero) on input parameters\n",
    "\n",
    "# objective\n",
    "if shape[-1]:\n",
    "    exec('from objective import objective{0} as objective'.format(shape[-1]))\n",
    "else: # z is single-valued\n",
    "    from mystic.models import rastrigin as objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d2887a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce objective function that caches multi-valued output\n",
    "model = mc.cached(archive=mname, multivalued=bool(shape[-1]))(objective)\n",
    "\n",
    "# get the cache (it stores the full multi-valued tuple)\n",
    "cache = model.__cache__()\n",
    "\n",
    "# get \"model inverse\" (for maximization)\n",
    "imodel = model.__inverse__\n",
    "\n",
    "# produce memoization function to cache 'solved' points \n",
    "memo = mc.cached(archive=ename, tol=etol, multivalued=bool(shape[-1]))(lambda x, **kwds: kwds['out'])\n",
    "\n",
    "# get the cache (for solved values)\n",
    "extrema = memo.__cache__()\n",
    "\n",
    "#XXX (apply logger?)\n",
    "\n",
    "def sample(axis=None, invert=False):\n",
    "    \"\"\"search (for minima) until terminated\n",
    "    \"\"\"#FIXME: {solver:directed or None}, {terminated:all, evals:1000}\n",
    "    if invert:\n",
    "        _model = imodel\n",
    "        l = -1\n",
    "    else:\n",
    "        _model = model\n",
    "        l = 1\n",
    "    if axis is None:\n",
    "        model_ = lambda x: _model(x)\n",
    "    else:\n",
    "        model_ = lambda x: _model(x, axis)\n",
    "    s = searcher(bounds, model_, npts=npts, solver=solver)\n",
    "    #print('sampling...')\n",
    "    s.sample_until(terminated=all) # npts=4 ==> ~800\n",
    "    #s.sample_until(terminated=any) # npts=4 ==> ~300\n",
    "    #s.sample_until(iters=20) # npts=500 -> 1000\n",
    "    #s.sample_until(evals=1) # npts=500 -> 1000\n",
    "    #s.sample(reset_all=False)\n",
    "    #print('done sampling...')\n",
    "    #NOTE: extract and save last points in the solver (nominally, the extrema)\n",
    "    if etol is not None: #XXX: use None to turn off caching 'solved' values?\n",
    "        slv = s._sampler._allSolvers\n",
    "        for _s in slv:\n",
    "            memo(_s.bestSolution, out=l*_s.bestEnergy)\n",
    "    return s\n",
    "\n",
    "def isample(axis=None):\n",
    "    \"\"\"search (for maxima) until terminated\n",
    "    \"\"\"#FIXME: {solver:directed or None}, {terminated:all, evals:1000}\n",
    "    return sample(axis=axis, invert=True)\n",
    "\n",
    "def _apply(f, arg):\n",
    "    \"\"\"call a function f with one argument arg\"\"\"\n",
    "    return f(arg)\n",
    "\n",
    "def search(axis, **kwds): #FIXME: axis=None, samplers=None\n",
    "    \"\"\"search for minima and maxima, until terminated\n",
    "\n",
    "    Inputs:\n",
    "      axis: int in [0,N], the axis of z to select\n",
    "      map: (parallel) map function \n",
    "    \"\"\" #XXX: other kwds to pass to sample/isample\n",
    "    _map = kwds.get('map', map)\n",
    "    fs = (sample, isample) #FIXME: accept list of samplers (don't hardwire)\n",
    "    return list(_map(_apply, fs, [axis]*len(fs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47f57a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump(objective, open('cost.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54ef5f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(dist, max=1e-4, ave=1e-5):\n",
    "    \"\"\"True if max(dist) <= max and ave(dist) <= ave\n",
    "    dist: numpy array of distances of shape (npoints,)\n",
    "    max: float, largest acceptable distance\n",
    "    ave: float, largest acceptable average of all distances\n",
    "    \"\"\"\n",
    "    return dist.max() <= max and dist.mean() <= ave\n",
    "\n",
    "def validate(x, z, axis, data=None, func=None, **kwds):\n",
    "    \"\"\"ensure function of (x,z) is valid with respect to all data\n",
    "\n",
    "    Inputs:\n",
    "      x: an array of shape (npts, dim) or (npts,)\n",
    "      z: an array of shape (npts, N) or (npts,)\n",
    "      axis: int in [0,N], the axis of z to select\n",
    "      data: a mystic.math.legacydata.dataset of legacy data\n",
    "      func: interpolated function z = f(*x) for data (x,z)\n",
    "\n",
    "    Additional Inputs:\n",
    "      warm: int, search until \"warm\" samples are taken (default is 0)\n",
    "      iters: int, abort after iters (default is inf)\n",
    "      retain: True if retain (x,z) in model cache (default is True)\n",
    "\n",
    "    Output:\n",
    "      returns tuple of (interpolated function, trained distance, test distance),\n",
    "      where trained distances is the graphical distance from the data to the\n",
    "      trained function, and test distance is the graphical distance from the\n",
    "      data to 'func' (the original function). If func is None, test distance\n",
    "      is returned as None.\n",
    "\n",
    "    NOTE:\n",
    "      additional keyword arguments are avaiable for interpolation. See\n",
    "      mystic.math.interpolate.interpf for more details.\n",
    "    \"\"\" # data,func single-valued\n",
    "    warm = kwds.get('warm', 0)\n",
    "    iters = kwds.get('iters', float('inf'))\n",
    "    retain = kwds.get('retain', True)\n",
    "    _tuple = lambda i: (tuple(i) if shape[-1] else i)\n",
    "    # get archived model evaluations\n",
    "    c = model.__cache__()\n",
    "    #ax = axify(axis)\n",
    "    # get inital data\n",
    "    if data is None or data is True: #FIXME: True is easter egg\n",
    "        _data = ds.from_archive(c, axis=None)\n",
    "    else:\n",
    "        _data = ds.from_archive(c, axis=None).load(data.coords, data.values) #XXX: new ids\n",
    "\n",
    "    # ensure data is \"warm\" (has desired number of points)\n",
    "    warm -= 0 if not x else len(unique(x)) #FIXME: x could be in c\n",
    "    while max(0, warm-len(c)): # while is 'not warm'\n",
    "        print('warming to {warm}...'.format(warm=warm))\n",
    "        # launch searchers\n",
    "        s = sum(s.evals() for s in search(axis)) #XXX: Pool().map?\n",
    "        print('{a}: evals:{e}, cache:{c}'.format(a=axis,e=s,c=len(c)))\n",
    "\n",
    "    # include desired points in cache\n",
    "    if not x:\n",
    "        pass\n",
    "    elif retain:\n",
    "        x,z = unique(x,z)\n",
    "        x,z = x.tolist(),[_tuple(i) for i in z]\n",
    "        for xi,zi in zip(x,z):\n",
    "            c.update({tuple(xi):zi}) #XXX: assumes 'clear' key,value\n",
    "    elif retain is None: #XXX: retain, but reevaluate z #FIXME: easter egg\n",
    "        x = unique(x).tolist()\n",
    "        z = [model(i) for i in x]\n",
    "    else: # temporarily include (x,z) in data\n",
    "        x,z = unique(x,z) #XXX: or pass?\n",
    "        x,z = x.tolist(),[_tuple(i) for i in z]\n",
    "\n",
    "    # load 'warmed' data from archive\n",
    "    # add new data points to the data\n",
    "    if data is None or data is True: #FIXME: True is easter egg\n",
    "        data = ds.from_archive(c, axis=None)\n",
    "    else:\n",
    "        data = ds.from_archive(c, axis=None).load(data.coords, data.values) #XXX: new ids\n",
    "    if x: data = data.load(x,z) # ids?\n",
    "    xx,zz = unique(data.coords, data.values)\n",
    "    data = ld.dataset().load(xx.tolist(),[_tuple(i) for i in zz]) #XXX: new ids\n",
    "    del xx,zz\n",
    "\n",
    "    # check for validity of the function\n",
    "    if func is None:\n",
    "        dist = np.array([np.inf]) # initialize as False\n",
    "        repeat = iters\n",
    "        while not valid(dist) and repeat:\n",
    "            print('training...')\n",
    "            # interpolate\n",
    "            m = Monitor()\n",
    "            m._x,m._y = data.coords,data.values\n",
    "            f = itp.Interpolator(m, **kwds).Interpolate(axis=axis)\n",
    "            # calculate distance/validity\n",
    "            dist = ds.distance(data, function=f, axis=axis)\n",
    "            repeat -= 1\n",
    "        if valid(dist):\n",
    "            print('train valid: max:{max}, mean:{mean}'.format(max=dist.max(), mean=dist.mean()))\n",
    "            return f, dist, None\n",
    "        #NOTE: this code should be reached only very rarely if at all\n",
    "        print('train invalid: max:{max}, mean:{mean}'.format(max=dist.max(), mean=dist.mean()))\n",
    "        # launch searchers\n",
    "        s = sum(s.evals() for s in search(axis)) #XXX: Pool().map?\n",
    "        print('{a}: evals:{e}, cache:{c}'.format(a=axis,e=s,c=len(c)))\n",
    "        res = validate(x,z, axis=axis, data=data, func=f, **kwds)\n",
    "        return res[0], res[1], None #XXX: None or dist?\n",
    "    else:\n",
    "        # calculate distance/validity\n",
    "        print('testing...')\n",
    "        dist = ds.distance(data, function=func, axis=axis)\n",
    "        if not valid(dist):\n",
    "            # recalculate with new function\n",
    "            print('test invalid: max:{max}, mean:{mean}'.format(max=dist.max(), mean=dist.mean()))\n",
    "            # get distance to the new data\n",
    "            _data = data.filter([not i for i in data.has_datapoint(_data)])\n",
    "            dist = ds.distance(_data, function=func, axis=axis)\n",
    "            del _data\n",
    "            #print('new invalid: max:{max}, mean:{mean}'.format(max=dist.max(), mean=dist.mean())) #NOTE: generally should be identical to 'test invalid'\n",
    "            res = validate(x,z, axis=axis, data=data, func=None, **kwds)\n",
    "            return res[0], res[1], dist\n",
    "        print('test valid: max:{max}, mean:{mean}'.format(max=dist.max(), mean=dist.mean()))\n",
    "        return func, None, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b776513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-08 22:19:01.865067\n"
     ]
    }
   ],
   "source": [
    "print(time.now())\n",
    "rb = mc.function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99b1bce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no new data points (x,z)\n"
     ]
    }
   ],
   "source": [
    "print('no new data points (x,z)')\n",
    "x,z = [],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc78005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning in thread-parallel\n",
      "warming to 1000...\n",
      "None: evals:158, cache:141\n",
      "warming to 1000...\n",
      "None: evals:138, cache:256\n",
      "warming to 1000...\n",
      "None: evals:153, cache:382\n",
      "warming to 1000...\n",
      "None: evals:154, cache:510\n",
      "warming to 1000...\n",
      "None: evals:135, cache:624\n",
      "warming to 1000...\n",
      "None: evals:135, cache:735\n",
      "warming to 1000...\n",
      "None: evals:170, cache:871\n",
      "warming to 1000...\n",
      "None: evals:154, cache:1000\n",
      "training...\n",
      "train valid: max:3.4891760584887526e-06, mean:6.194231892972902e-07\n",
      "None: no stored function\n",
      "endpoints: 22 of 22\n",
      "score: None\n",
      "warming to 2000...\n",
      "None: evals:147, cache:1120\n",
      "warming to 2000...\n",
      "None: evals:143, cache:1236\n",
      "warming to 2000...\n",
      "None: evals:152, cache:1376\n",
      "warming to 2000...\n",
      "None: evals:166, cache:1523\n",
      "warming to 2000...\n",
      "None: evals:145, cache:1639\n",
      "warming to 2000...\n",
      "None: evals:155, cache:1766\n",
      "warming to 2000...\n",
      "None: evals:141, cache:1880\n",
      "warming to 2000...\n",
      "None: evals:191, cache:2039\n",
      "testing...\n",
      "test invalid: max:0.19888509484767625, mean:0.036859222150737544\n",
      "training...\n",
      "train valid: max:3.815079812968327e-07, mean:6.11526085216526e-08\n",
      "None: replace stored function\n",
      "endpoints: 18 of 40\n",
      "score: 0.036859222150737544\n",
      "warming to 3000...\n",
      "None: evals:184, cache:2177\n",
      "warming to 3000...\n",
      "None: evals:153, cache:2304\n",
      "warming to 3000...\n",
      "None: evals:167, cache:2441\n",
      "warming to 3000...\n",
      "None: evals:139, cache:2557\n",
      "warming to 3000...\n",
      "None: evals:140, cache:2673\n",
      "warming to 3000...\n",
      "None: evals:143, cache:2790\n",
      "warming to 3000...\n",
      "None: evals:146, cache:2912\n",
      "warming to 3000...\n",
      "None: evals:173, cache:3068\n",
      "testing...\n",
      "test invalid: max:0.16779929196697188, mean:0.013534780384906036\n",
      "training...\n",
      "train valid: max:1.1009112036899988e-06, mean:1.091324293243089e-07\n",
      "None: replace stored function\n",
      "endpoints: 14 of 54\n",
      "score: 0.013534780384906036\n",
      "warming to 4000...\n",
      "None: evals:149, cache:3186\n",
      "warming to 4000...\n",
      "None: evals:165, cache:3318\n",
      "warming to 4000...\n",
      "None: evals:175, cache:3466\n",
      "warming to 4000...\n",
      "None: evals:159, cache:3600\n",
      "warming to 4000...\n",
      "None: evals:149, cache:3721\n",
      "warming to 4000...\n",
      "None: evals:162, cache:3854\n",
      "warming to 4000...\n",
      "None: evals:142, cache:3972\n",
      "warming to 4000...\n",
      "None: evals:142, cache:4087\n",
      "testing...\n",
      "test invalid: max:0.21208058286802103, mean:0.009882127249119979\n",
      "training...\n",
      "train valid: max:1.7277891473922565e-05, mean:2.3815535986728417e-06\n",
      "None: replace stored function\n",
      "endpoints: 16 of 70\n",
      "score: 0.009882127249119979\n",
      "warming to 5000...\n",
      "None: evals:155, cache:4210\n",
      "warming to 5000...\n",
      "None: evals:148, cache:4344\n",
      "warming to 5000...\n",
      "None: evals:145, cache:4461\n",
      "warming to 5000...\n",
      "None: evals:144, cache:4576\n",
      "warming to 5000...\n",
      "None: evals:161, cache:4710\n",
      "warming to 5000...\n",
      "None: evals:140, cache:4834\n",
      "warming to 5000...\n"
     ]
    }
   ],
   "source": [
    "# get handles to func_DBs\n",
    "if shape[-1]:\n",
    "    archives = list(map(lambda i: rb.db('func{i}.db'.format(i=i)), range(shape[-1])))\n",
    "else:\n",
    "    archives = rb.db('func.db')\n",
    "# check for stored func in func_db, and if not found\n",
    "# generate a dummy interpf to store results\n",
    "func = rb.read(archives)\n",
    "\n",
    "it = 10   # this is number of refit tries before 'fail' to sampling\n",
    "w = 1000  # this is size of 'warm' #FIXME: rastrigin\n",
    "y = len(model.__cache__())\n",
    "w *= (1 + (y // w))  # warm in increments of 'w'\n",
    "\n",
    "if shape[-1]:\n",
    "    hist = dict((i,[]) for i in range(shape[-1]))\n",
    "    warm = [w]*shape[-1]\n",
    "else:\n",
    "    hist = {None:[]}\n",
    "    warm = [w]\n",
    "size = []\n",
    "\n",
    "d = [True] # this is data=None or data=True\n",
    "\n",
    "if shape[-1]:\n",
    "    do = lambda : (lambda i: d[i])(0)\n",
    "    xyz = lambda i: validate(x, z, axis=i, data=do(), func=func.__axis__[i], warm=warm[i], method='thin_plate', iters=it) #XXX: epsilon?\n",
    "else:\n",
    "    do = lambda : (lambda i: d[0])(0)\n",
    "    xyz = lambda i: validate(x, z, axis=None, data=do(), func=func, warm=warm[0], method='thin_plate', iters=it) #XXX: epsilon?\n",
    "\n",
    "\n",
    "def xxx(i):\n",
    "    # 'validate' a function\n",
    "    _f,_d,_t = xyz(i)\n",
    "    # save 'test' distance\n",
    "    if _t is not None and _d is not None:\n",
    "        hist[i].append(_t.mean()) #FIXME: mean or max? or sum?\n",
    "        #hist[i].append(_t.max()) #FIXME: mean or max? or sum?\n",
    "    # read data from (cached) run archive\n",
    "    if (shape[-1] and None in func.__axis__) or (func is None):\n",
    "        print('{i}: no stored function'.format(i=i))\n",
    "        return (_f,_d,_t)[0]\n",
    "    if _d is None:\n",
    "        print('{i}: retain stored function'.format(i=i))\n",
    "        return (func.__axis__[i],_t)[0] if shape[-1] else (func,_t)[0]\n",
    "\n",
    "    c = model.__cache__()\n",
    "    data = ds.from_archive(c, axis=None) #XXX: axis?\n",
    "    # calculate dist from data to func\n",
    "    dist = ds.distance(data, function=func, axis=None) #XXX: axis?\n",
    "    # keep the func with the smaller 'trained' distance\n",
    "    _d, d = _d.sum(), dist[i].sum()\n",
    "    if _d < d:\n",
    "        print('{i}: replace stored function'.format(i=i))\n",
    "        return (_f,_d,_t)[0]\n",
    "    print('{i}: retain stored function'.format(i=i))\n",
    "    return (func.__axis__[i],d,_t)[0] if shape[-1] else (func,d,_t)[0]\n",
    "\n",
    "pool = mp.Pool()\n",
    "smap = pool.map\n",
    "#smap = lambda *args,**kwds: list(map(*args, **kwds))\n",
    "\n",
    "print('learning in thread-parallel')\n",
    "null = float('nan')\n",
    "tol = 2e-4 #FIXME: better than rep iters <= tol, should stop when rep converges #FIXME: rastrigin\n",
    "rep = 3  #NOTE: this is hist.values()[-rep:] <= tol\n",
    "last = 3  #NOTE: this is any(size[-last:])\n",
    "loops = 30 #FIXME: rastrigin\n",
    "done = False\n",
    "start = loops\n",
    "\n",
    "\n",
    "save = LoggingMonitor(1, 'score.txt')\n",
    "\n",
    "while not done and loops:\n",
    "    if shape[-1]:\n",
    "        func.__axis__[:] = smap(xxx, range(shape[-1]))  # data=True, func=None\n",
    "    else:\n",
    "        func = smap(xxx, [None])[0]\n",
    "    rb.write(func, archives)\n",
    "    # get size of 'terminated' points archive\n",
    "    size.append(len(mc.archive.read(ename)) - sum(size))\n",
    "    print('endpoints: {0} of {1}'.format(size[-1], sum(size)))\n",
    "    # check for 'terminated' stop\n",
    "    _done = False if last > len(size) else not any(size[-last:])\n",
    "    # check for 'testing' stop\n",
    "    done = [hi[-rep:] for hi in hist.values() if len(hi)]\n",
    "    if not len(done):\n",
    "        score = float('nan')\n",
    "        save(warm[:1], score) #NOTE: currently all warm[i] are the same\n",
    "        print('score: None')\n",
    "        done = False\n",
    "    else:\n",
    "        score = sum([hi[-1] for hi in done])/len(done)\n",
    "        save(warm[:1], score) #NOTE: currently all warm[i] are the same\n",
    "        print('score: {mx}'.format(mx=score))\n",
    "        score = max([max(hi) for hi in done])\n",
    "        done = False if (len(done) < len(hist)) else score <= tol\n",
    "    done = _done or done #XXX: or? and?\n",
    "    if not done:\n",
    "        for i,wi in enumerate(warm):\n",
    "            warm[i] = wi + w \n",
    "    loops -= 1\n",
    "\n",
    "pool.close(); pool.join()\n",
    "\n",
    "# double-checking that final functions are valid\n",
    "\n",
    "data = ds.from_archive(model.__cache__(), axis=None)\n",
    "for f in (func.__axis__ if shape[-1] else [func]):\n",
    "    dist = ds.distance(data, function=f)#, axis=None)\n",
    "    assert valid(dist)\n",
    "    print('valid: OK')\n",
    "\n",
    "print('historical testing misfit') #FIXME: mean or max? or sum?\n",
    "\n",
    "\n",
    "for ii,h in hist.items():\n",
    "    print('{ii}: {h}'.format(ii=ii, h=np.array(h)))\n",
    "\n",
    "print('historical endpoint cache size')\n",
    "\n",
    "\n",
    "size[:] = list(it.accumulate(size))\n",
    "print(size)\n",
    "\n",
    "\n",
    "dill.dump(hist, open('hist.pkl', 'wb'))\n",
    "dill.dump(size, open('size.pkl', 'wb'))\n",
    "print(time.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70ca21d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9c0fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime as time\n",
    "import dill\n",
    "# apply cache/archive in 3D same as 1D\n",
    "import mystic.cache as mc\n",
    "import dataset as ds\n",
    "import mystic.math.legacydata as ld\n",
    "from mystic.math.interpolate import _unique as unique\n",
    "import interpolator as itp\n",
    "from mystic.monitors import Monitor\n",
    "import dataset as ds\n",
    "import multiprocess.dummy as mp #FIXME: fails processes\n",
    "from mystic.monitors import LoggingMonitor\n",
    "import itertools as it\n",
    "# select solver and searcher algorithms\n",
    "from mystic.solvers import NelderMeadSimplexSolver as solver\n",
    "from mystic.samplers import *\n",
    "searcher = SparsitySampler\n",
    "#searcher = BuckshotSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7dac6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (2,0) #FIXME: rastrigin\n",
    "\n",
    "mname = 'demo'  # dynamic 'model' name\n",
    "fname = 'dirty' # static 'data' name\n",
    "pname = 'demo'  # hyper_plot name\n",
    "ename = 'stop'  # termination name\n",
    "\n",
    "etol = 1 # None # int rounding precision for termination point cache\n",
    "npts = 2 # 125 #125 #2 #500 # number of solvers used in a searcher\n",
    "upper = 10 #FIXME: 1000  # upper bound on input parameters\n",
    "bounds = [(0.,upper)] * shape[0] # bounds (lower is zero) on input parameters\n",
    "\n",
    "# objective\n",
    "if shape[-1]:\n",
    "    exec('from objective import objective{0} as objective'.format(shape[-1]))\n",
    "else: # z is single-valued\n",
    "    from mystic.models import rastrigin as objective\n",
    "#     from dca import gstr as objective\n",
    "    #from perlin_nick import MultiscaleNDFunc\n",
    "    #objective = MultiscaleNDFunc(1, 20, 100, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f678a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce objective function that caches multi-valued output\n",
    "model = mc.cached(archive=mname, multivalued=bool(shape[-1]))(objective)\n",
    "\n",
    "# get the cache (it stores the full multi-valued tuple)\n",
    "cache = model.__cache__()\n",
    "\n",
    "# get \"model inverse\" (for maximization)\n",
    "imodel = model.__inverse__\n",
    "\n",
    "# produce memoization function to cache 'solved' points \n",
    "memo = mc.cached(archive=ename, tol=etol, multivalued=bool(shape[-1]))(lambda x, **kwds: kwds['out'])\n",
    "\n",
    "# get the cache (for solved values)\n",
    "extrema = memo.__cache__()\n",
    "\n",
    "#XXX (apply logger?)\n",
    "\n",
    "def sample(axis=None, invert=False):\n",
    "    \"\"\"search (for minima) until terminated\n",
    "    \"\"\"#FIXME: {solver:directed or None}, {terminated:all, evals:1000}\n",
    "    if invert:\n",
    "        _model = imodel\n",
    "        l = -1\n",
    "    else:\n",
    "        _model = model\n",
    "        l = 1\n",
    "    if axis is None:\n",
    "        model_ = lambda x: _model(x)\n",
    "    else:\n",
    "        model_ = lambda x: _model(x, axis)\n",
    "    s = searcher(bounds, model_, npts=npts, solver=solver)\n",
    "    #print('sampling...')\n",
    "    s.sample_until(terminated=all) # npts=4 ==> ~800\n",
    "    #s.sample_until(terminated=any) # npts=4 ==> ~300\n",
    "    #s.sample_until(iters=20) # npts=500 -> 1000\n",
    "    #s.sample_until(evals=1) # npts=500 -> 1000\n",
    "    #s.sample(reset_all=False)\n",
    "    #print('done sampling...')\n",
    "    #NOTE: extract and save last points in the solver (nominally, the extrema)\n",
    "    if etol is not None: #XXX: use None to turn off caching 'solved' values?\n",
    "        slv = s._sampler._allSolvers\n",
    "        for _s in slv:\n",
    "            memo(_s.bestSolution, out=l*_s.bestEnergy)\n",
    "    return s\n",
    "\n",
    "def isample(axis=None):\n",
    "    \"\"\"search (for maxima) until terminated\n",
    "    \"\"\"#FIXME: {solver:directed or None}, {terminated:all, evals:1000}\n",
    "    return sample(axis=axis, invert=True)\n",
    "\n",
    "def _apply(f, arg):\n",
    "    \"\"\"call a function f with one argument arg\"\"\"\n",
    "    return f(arg)\n",
    "\n",
    "def search(axis, **kwds): #FIXME: axis=None, samplers=None\n",
    "    \"\"\"search for minima and maxima, until terminated\n",
    "\n",
    "    Inputs:\n",
    "      axis: int in [0,N], the axis of z to select\n",
    "      map: (parallel) map function \n",
    "    \"\"\" #XXX: other kwds to pass to sample/isample\n",
    "    _map = kwds.get('map', map)\n",
    "    fs = (sample, isample) #FIXME: accept list of samplers (don't hardwire)\n",
    "    return list(_map(_apply, fs, [axis]*len(fs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f8b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump(objective, open('cost.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d32bb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-08 22:09:02.599350\n"
     ]
    }
   ],
   "source": [
    "def valid(dist, max=1e-4, ave=1e-5):\n",
    "    \"\"\"True if max(dist) <= max and ave(dist) <= ave\n",
    "    dist: numpy array of distances of shape (npoints,)\n",
    "    max: float, largest acceptable distance\n",
    "    ave: float, largest acceptable average of all distances\n",
    "    \"\"\"\n",
    "    return dist.max() <= max and dist.mean() <= ave\n",
    "\n",
    "def validate(x, z, axis, data=None, func=None, **kwds):\n",
    "    \"\"\"ensure function of (x,z) is valid with respect to all data\n",
    "\n",
    "    Inputs:\n",
    "      x: an array of shape (npts, dim) or (npts,)\n",
    "      z: an array of shape (npts, N) or (npts,)\n",
    "      axis: int in [0,N], the axis of z to select\n",
    "      data: a mystic.math.legacydata.dataset of legacy data\n",
    "      func: interpolated function z = f(*x) for data (x,z)\n",
    "\n",
    "    Additional Inputs:\n",
    "      warm: int, search until \"warm\" samples are taken (default is 0)\n",
    "      iters: int, abort after iters (default is inf)\n",
    "      retain: True if retain (x,z) in model cache (default is True)\n",
    "\n",
    "    Output:\n",
    "      returns tuple of (interpolated function, trained distance, test distance),\n",
    "      where trained distances is the graphical distance from the data to the\n",
    "      trained function, and test distance is the graphical distance from the\n",
    "      data to 'func' (the original function). If func is None, test distance\n",
    "      is returned as None.\n",
    "\n",
    "    NOTE:\n",
    "      additional keyword arguments are avaiable for interpolation. See\n",
    "      mystic.math.interpolate.interpf for more details.\n",
    "    \"\"\" # data,func single-valued\n",
    "    warm = kwds.get('warm', 0)\n",
    "    iters = kwds.get('iters', float('inf'))\n",
    "    retain = kwds.get('retain', True)\n",
    "    _tuple = lambda i: (tuple(i) if shape[-1] else i)\n",
    "    # get archived model evaluations\n",
    "    c = model.__cache__()\n",
    "    #ax = axify(axis)\n",
    "    # get inital data\n",
    "    if data is None or data is True: #FIXME: True is easter egg\n",
    "        _data = ds.from_archive(c, axis=None)\n",
    "    else:\n",
    "        _data = ds.from_archive(c, axis=None).load(data.coords, data.values) #XXX: new ids\n",
    "\n",
    "    # ensure data is \"warm\" (has desired number of points)\n",
    "    warm -= 0 if not x else len(unique(x)) #FIXME: x could be in c\n",
    "    while max(0, warm-len(c)): # while is 'not warm'\n",
    "        print('warming to {warm}...'.format(warm=warm))\n",
    "        # launch searchers\n",
    "        s = sum(s.evals() for s in search(axis)) #XXX: Pool().map?\n",
    "        print('{a}: evals:{e}, cache:{c}'.format(a=axis,e=s,c=len(c)))\n",
    "\n",
    "    # include desired points in cache\n",
    "    if not x:\n",
    "        pass\n",
    "    elif retain:\n",
    "        x,z = unique(x,z)\n",
    "        x,z = x.tolist(),[_tuple(i) for i in z]\n",
    "        for xi,zi in zip(x,z):\n",
    "            c.update({tuple(xi):zi}) #XXX: assumes 'clear' key,value\n",
    "    elif retain is None: #XXX: retain, but reevaluate z #FIXME: easter egg\n",
    "        x = unique(x).tolist()\n",
    "        z = [model(i) for i in x]\n",
    "    else: # temporarily include (x,z) in data\n",
    "        x,z = unique(x,z) #XXX: or pass?\n",
    "        x,z = x.tolist(),[_tuple(i) for i in z]\n",
    "\n",
    "    # load 'warmed' data from archive\n",
    "    # add new data points to the data\n",
    "    if data is None or data is True: #FIXME: True is easter egg\n",
    "        data = ds.from_archive(c, axis=None)\n",
    "    else:\n",
    "        data = ds.from_archive(c, axis=None).load(data.coords, data.values) #XXX: new ids\n",
    "    if x: data = data.load(x,z) # ids?\n",
    "    xx,zz = unique(data.coords, data.values)\n",
    "    data = ld.dataset().load(xx.tolist(),[_tuple(i) for i in zz]) #XXX: new ids\n",
    "    del xx,zz\n",
    "\n",
    "    # check for validity of the function\n",
    "    if func is None:\n",
    "        dist = np.array([np.inf]) # initialize as False\n",
    "        repeat = iters\n",
    "        while not valid(dist) and repeat:\n",
    "            print('training...')\n",
    "            # interpolate\n",
    "            m = Monitor()\n",
    "            m._x,m._y = data.coords,data.values\n",
    "            f = itp.Interpolator(m, **kwds).Interpolate(axis=axis)\n",
    "            # calculate distance/validity\n",
    "            dist = ds.distance(data, function=f, axis=axis)\n",
    "            repeat -= 1\n",
    "        if valid(dist):\n",
    "            print('train valid: max:{max}, mean:{mean}'.format(max=dist.max(), mean=dist.mean()))\n",
    "            return f, dist, None\n",
    "        #NOTE: this code should be reached only very rarely if at all\n",
    "        print('train invalid: max:{max}, mean:{mean}'.format(max=dist.max(), mean=dist.mean()))\n",
    "        # launch searchers\n",
    "        s = sum(s.evals() for s in search(axis)) #XXX: Pool().map?\n",
    "        print('{a}: evals:{e}, cache:{c}'.format(a=axis,e=s,c=len(c)))\n",
    "        res = validate(x,z, axis=axis, data=data, func=f, **kwds)\n",
    "        return res[0], res[1], None #XXX: None or dist?\n",
    "    else:\n",
    "        # calculate distance/validity\n",
    "        print('testing...')\n",
    "        dist = ds.distance(data, function=func, axis=axis)\n",
    "        if not valid(dist):\n",
    "            # recalculate with new function\n",
    "            print('test invalid: max:{max}, mean:{mean}'.format(max=dist.max(), mean=dist.mean()))\n",
    "            # get distance to the new data\n",
    "            _data = data.filter([not i for i in data.has_datapoint(_data)])\n",
    "            dist = ds.distance(_data, function=func, axis=axis)\n",
    "            del _data\n",
    "            #print('new invalid: max:{max}, mean:{mean}'.format(max=dist.max(), mean=dist.mean())) #NOTE: generally should be identical to 'test invalid'\n",
    "            res = validate(x,z, axis=axis, data=data, func=None, **kwds)\n",
    "            return res[0], res[1], dist\n",
    "        print('test valid: max:{max}, mean:{mean}'.format(max=dist.max(), mean=dist.mean()))\n",
    "        return func, None, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ce279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.now())\n",
    "rb = mc.function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438cf5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('no new data points (x,z)')\n",
    "x,z = [],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdaa5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no new data points (x,z)\n",
      "learning in thread-parallel\n",
      "warming to 3000...\n",
      "None: evals:625, cache:2337\n",
      "warming to 3000...\n",
      "None: evals:245, cache:2514\n",
      "warming to 3000...\n",
      "None: evals:270, cache:2704\n",
      "warming to 3000...\n",
      "None: evals:314, cache:2939\n",
      "warming to 3000...\n",
      "None: evals:306, cache:3195\n",
      "testing...\n",
      "test invalid: max:0.22039148122470725, mean:0.023742983770643687\n",
      "training...\n",
      "train valid: max:7.704621358145941e-07, mean:1.2205990569576636e-07\n",
      "None: replace stored function\n",
      "endpoints: 51 of 51\n",
      "score: 0.023742983770643687\n",
      "warming to 6000...\n",
      "None: evals:273, cache:3405\n",
      "warming to 6000...\n",
      "None: evals:283, cache:3634\n",
      "warming to 6000...\n",
      "None: evals:371, cache:3912\n",
      "warming to 6000...\n",
      "None: evals:311, cache:4147\n",
      "warming to 6000...\n",
      "None: evals:669, cache:4529\n",
      "warming to 6000...\n",
      "None: evals:319, cache:4774\n",
      "warming to 6000...\n",
      "None: evals:212, cache:4939\n",
      "warming to 6000...\n",
      "None: evals:267, cache:5125\n",
      "warming to 6000...\n",
      "None: evals:326, cache:5371\n",
      "warming to 6000...\n",
      "None: evals:277, cache:5587\n",
      "warming to 6000...\n",
      "None: evals:289, cache:5801\n",
      "warming to 6000...\n",
      "None: evals:339, cache:6053\n",
      "testing...\n",
      "test invalid: max:0.17970402202070238, mean:0.01649909611270368\n",
      "training...\n",
      "train valid: max:3.9469345329643197e-07, mean:5.0688100141479194e-08\n",
      "None: replace stored function\n",
      "endpoints: 35 of 86\n",
      "score: 0.01649909611270368\n",
      "warming to 9000...\n",
      "None: evals:265, cache:6244\n",
      "warming to 9000...\n",
      "None: evals:310, cache:6479\n",
      "warming to 9000...\n",
      "None: evals:268, cache:6676\n",
      "warming to 9000...\n",
      "None: evals:275, cache:6870\n",
      "warming to 9000...\n"
     ]
    }
   ],
   "source": [
    "# get handles to func_DBs\n",
    "if shape[-1]:\n",
    "    archives = list(map(lambda i: rb.db('func{i}.db'.format(i=i)), range(shape[-1])))\n",
    "else:\n",
    "    archives = rb.db('func.db')\n",
    "# check for stored func in func_db, and if not found\n",
    "# generate a dummy interpf to store results\n",
    "func = rb.read(archives)\n",
    "\n",
    "it = 10   # this is number of refit tries before 'fail' to sampling\n",
    "w = 1000  # this is size of 'warm' #FIXME: rastrigin\n",
    "y = len(model.__cache__())\n",
    "w *= (1 + (y // w))  # warm in increments of 'w'\n",
    "\n",
    "if shape[-1]:\n",
    "    hist = dict((i,[]) for i in range(shape[-1]))\n",
    "    warm = [w]*shape[-1]\n",
    "else:\n",
    "    hist = {None:[]}\n",
    "    warm = [w]\n",
    "size = []\n",
    "\n",
    "d = [True] # this is data=None or data=True\n",
    "\n",
    "if shape[-1]:\n",
    "    do = lambda : (lambda i: d[i])(0)\n",
    "    xyz = lambda i: validate(x, z, axis=i, data=do(), func=func.__axis__[i], warm=warm[i], method='thin_plate', iters=it) #XXX: epsilon?\n",
    "else:\n",
    "    do = lambda : (lambda i: d[0])(0)\n",
    "    xyz = lambda i: validate(x, z, axis=None, data=do(), func=func, warm=warm[0], method='thin_plate', iters=it) #XXX: epsilon?\n",
    "\n",
    "\n",
    "def xxx(i):\n",
    "    # 'validate' a function\n",
    "    _f,_d,_t = xyz(i)\n",
    "    # save 'test' distance\n",
    "    if _t is not None and _d is not None:\n",
    "        hist[i].append(_t.mean()) #FIXME: mean or max? or sum?\n",
    "        #hist[i].append(_t.max()) #FIXME: mean or max? or sum?\n",
    "    # read data from (cached) run archive\n",
    "    if (shape[-1] and None in func.__axis__) or (func is None):\n",
    "        print('{i}: no stored function'.format(i=i))\n",
    "        return (_f,_d,_t)[0]\n",
    "    if _d is None:\n",
    "        print('{i}: retain stored function'.format(i=i))\n",
    "        return (func.__axis__[i],_t)[0] if shape[-1] else (func,_t)[0]\n",
    "\n",
    "    c = model.__cache__()\n",
    "    data = ds.from_archive(c, axis=None) #XXX: axis?\n",
    "    # calculate dist from data to func\n",
    "    dist = ds.distance(data, function=func, axis=None) #XXX: axis?\n",
    "    # keep the func with the smaller 'trained' distance\n",
    "    _d, d = _d.sum(), dist[i].sum()\n",
    "    if _d < d:\n",
    "        print('{i}: replace stored function'.format(i=i))\n",
    "        return (_f,_d,_t)[0]\n",
    "    print('{i}: retain stored function'.format(i=i))\n",
    "    return (func.__axis__[i],d,_t)[0] if shape[-1] else (func,d,_t)[0]\n",
    "\n",
    "pool = mp.Pool()\n",
    "smap = pool.map\n",
    "#smap = lambda *args,**kwds: list(map(*args, **kwds))\n",
    "\n",
    "print('learning in thread-parallel')\n",
    "null = float('nan')\n",
    "tol = 2e-4 #FIXME: better than rep iters <= tol, should stop when rep converges #FIXME: rastrigin\n",
    "rep = 3  #NOTE: this is hist.values()[-rep:] <= tol\n",
    "last = 3  #NOTE: this is any(size[-last:])\n",
    "loops = 30 #FIXME: rastrigin\n",
    "done = False\n",
    "start = loops\n",
    "\n",
    "\n",
    "save = LoggingMonitor(1, 'score.txt')\n",
    "\n",
    "while not done and loops:\n",
    "    if shape[-1]:\n",
    "        func.__axis__[:] = smap(xxx, range(shape[-1]))  # data=True, func=None\n",
    "    else:\n",
    "        func = smap(xxx, [None])[0]\n",
    "    rb.write(func, archives)\n",
    "    # get size of 'terminated' points archive\n",
    "    size.append(len(mc.archive.read(ename)) - sum(size))\n",
    "    print('endpoints: {0} of {1}'.format(size[-1], sum(size)))\n",
    "    # check for 'terminated' stop\n",
    "    _done = False if last > len(size) else not any(size[-last:])\n",
    "    # check for 'testing' stop\n",
    "    done = [hi[-rep:] for hi in hist.values() if len(hi)]\n",
    "    if not len(done):\n",
    "        score = float('nan')\n",
    "        save(warm[:1], score) #NOTE: currently all warm[i] are the same\n",
    "        print('score: None')\n",
    "        done = False\n",
    "    else:\n",
    "        score = sum([hi[-1] for hi in done])/len(done)\n",
    "        save(warm[:1], score) #NOTE: currently all warm[i] are the same\n",
    "        print('score: {mx}'.format(mx=score))\n",
    "        score = max([max(hi) for hi in done])\n",
    "        done = False if (len(done) < len(hist)) else score <= tol\n",
    "    done = _done or done #XXX: or? and?\n",
    "    if not done:\n",
    "        for i,wi in enumerate(warm):\n",
    "            warm[i] = wi + w \n",
    "    loops -= 1\n",
    "\n",
    "pool.close(); pool.join()\n",
    "\n",
    "# double-checking that final functions are valid\n",
    "\n",
    "data = ds.from_archive(model.__cache__(), axis=None)\n",
    "for f in (func.__axis__ if shape[-1] else [func]):\n",
    "    dist = ds.distance(data, function=f)#, axis=None)\n",
    "    assert valid(dist)\n",
    "    print('valid: OK')\n",
    "\n",
    "print('historical testing misfit') #FIXME: mean or max? or sum?\n",
    "\n",
    "\n",
    "for ii,h in hist.items():\n",
    "    print('{ii}: {h}'.format(ii=ii, h=np.array(h)))\n",
    "\n",
    "print('historical endpoint cache size')\n",
    "\n",
    "\n",
    "size[:] = list(it.accumulate(size))\n",
    "print(size)\n",
    "\n",
    "\n",
    "dill.dump(hist, open('hist.pkl', 'wb'))\n",
    "dill.dump(size, open('size.pkl', 'wb'))\n",
    "print(time.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba48e41d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
